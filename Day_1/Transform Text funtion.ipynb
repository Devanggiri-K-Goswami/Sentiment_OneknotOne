{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f20cc3bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LENOVO\\anaconda3\\lib\\site-packages\\scipy\\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "from tracemalloc import stop\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c2716d4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Error loading punkt: <urlopen error [Errno 11001]\n",
      "[nltk_data]     getaddrinfo failed>\n",
      "[nltk_data] Error loading stopwords: <urlopen error [Errno 11001]\n",
      "[nltk_data]     getaddrinfo failed>\n"
     ]
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "sw=nltk.corpus.stopwords.words(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a80506a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: emoji in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (1.7.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -pencv-python-headless (c:\\users\\lenovo\\appdata\\roaming\\python\\python39\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pencv-python-headless (c:\\users\\lenovo\\appdata\\roaming\\python\\python39\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pencv-python-headless (c:\\users\\lenovo\\appdata\\roaming\\python\\python39\\site-packages)\n",
      "WARNING: Error parsing requirements for pyqt5: [Errno 2] No such file or directory: 'c:\\\\users\\\\lenovo\\\\anaconda3\\\\lib\\\\site-packages\\\\PyQt5-5.15.7.dist-info\\\\METADATA'\n",
      "WARNING: Ignoring invalid distribution -pencv-python-headless (c:\\users\\lenovo\\appdata\\roaming\\python\\python39\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pencv-python-headless (c:\\users\\lenovo\\appdata\\roaming\\python\\python39\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pencv-python-headless (c:\\users\\lenovo\\appdata\\roaming\\python\\python39\\site-packages)\n",
      "\n",
      "[notice] A new release of pip available: 22.2.2 -> 23.1.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install emoji\n",
    "import emoji\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9b67dfb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "d740dc06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (3.2.5)\n",
      "Collecting nltk\n",
      "  Downloading nltk-3.8.1-py3-none-any.whl (1.5 MB)\n",
      "     ---------------------------------------- 1.5/1.5 MB 835.0 kB/s eta 0:00:00\n",
      "Requirement already satisfied: joblib in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from nltk) (1.1.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from nltk) (4.62.3)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from nltk) (2021.8.3)\n",
      "Requirement already satisfied: click in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from nltk) (7.1.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from tqdm->nltk) (0.4.4)\n",
      "Installing collected packages: nltk\n",
      "  Attempting uninstall: nltk\n",
      "    Found existing installation: nltk 3.2.5\n",
      "    Uninstalling nltk-3.2.5:\n",
      "      Successfully uninstalled nltk-3.2.5\n",
      "Successfully installed nltk-3.8.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -pencv-python-headless (c:\\users\\lenovo\\appdata\\roaming\\python\\python39\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pencv-python-headless (c:\\users\\lenovo\\appdata\\roaming\\python\\python39\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pencv-python-headless (c:\\users\\lenovo\\appdata\\roaming\\python\\python39\\site-packages)\n",
      "WARNING: Error parsing requirements for pyqt5: [Errno 2] No such file or directory: 'c:\\\\users\\\\lenovo\\\\anaconda3\\\\lib\\\\site-packages\\\\PyQt5-5.15.7.dist-info\\\\METADATA'\n",
      "    WARNING: Ignoring invalid distribution -pencv-python-headless (c:\\users\\lenovo\\appdata\\roaming\\python\\python39\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pencv-python-headless (c:\\users\\lenovo\\appdata\\roaming\\python\\python39\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pencv-python-headless (c:\\users\\lenovo\\appdata\\roaming\\python\\python39\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pencv-python-headless (c:\\users\\lenovo\\appdata\\roaming\\python\\python39\\site-packages)\n",
      "\n",
      "[notice] A new release of pip available: 22.2.2 -> 23.1.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d5963b69",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "94599012",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\LENOVO\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.data.path.append('D:\\OneKnotOne_Internship\\Day_1\\nltk_data')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "e57798ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "ce1a0785",
   "metadata": {},
   "outputs": [],
   "source": [
    "wnl = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "2b48bfb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# text=\"Hello this' is?? the best !!case!!!\"\n",
    "# text=\"Logan Paul it's yo big day ‼️‼️\"\n",
    "# text=\"this looks like great video after done would kind enough check' ???? youtube channel!! give some feedback maybe even subscribing\"\n",
    "# text='This is wrost example ever and whatever you are doing that is more use for u'\n",
    "text = \"Why are you laughing!!! her'e ???? because this is most serious problem which happens more and less but you shold have to face this continuously\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "078976f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'laughing here because this most serious problem which happens more less shold have face this continuously'"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp_=[]\n",
    "for i in text:\n",
    "    if i not in string.punctuation:\n",
    "         tmp_.append(i)\n",
    "text = ''.join(tmp_)\n",
    "text = re.sub('[^A-Za-z ]+', '', text)\n",
    "text=text.strip()\n",
    "text = ' '.join([w for w in text.split() if len(w)>3])\n",
    "text = text.lower()\n",
    "# text = text.split()\n",
    "# text = [wnl.lemmatize(i) for i in text if i not in set(stopwords.words('english'))]\n",
    "# text = ' '.join(text)\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "59301c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lemmatized_word = wnl.lemmatize('laughing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "66ccedaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'laughing here because this most serious problem which happens more less shold have face this continuously'"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "634e985b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "845127c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5374a4d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28866ec8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b52c7bf2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88bf2a87",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a675fdac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e2f4f23",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ed236f4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
