{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from IPython.display import Image\n",
    "# Image(filename=r\"C:\\\\Users\\\\amanr\\\\OneDrive\\\\Desktop\\\\12.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import re\n",
    "import string\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report, f1_score, accuracy_score, confusion_matrix\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Import and preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "TeweetData = pd.read_csv(r\"Tweets.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>airline_sentiment_confidence</th>\n",
       "      <th>negativereason</th>\n",
       "      <th>negativereason_confidence</th>\n",
       "      <th>airline</th>\n",
       "      <th>airline_sentiment_gold</th>\n",
       "      <th>name</th>\n",
       "      <th>negativereason_gold</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>text</th>\n",
       "      <th>tweet_coord</th>\n",
       "      <th>tweet_created</th>\n",
       "      <th>tweet_location</th>\n",
       "      <th>user_timezone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.703010e+17</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.3486</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24-02-2015 11:15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.703010e+17</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Bad Flight</td>\n",
       "      <td>0.7033</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica it's really aggressive to blast...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24-02-2015 11:15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.703010e+17</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Can't Tell</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica and it's a really big bad thing...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24-02-2015 11:14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.703010e+17</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Can't Tell</td>\n",
       "      <td>0.6842</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica seriously would pay $30 a fligh...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24-02-2015 11:14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.703010e+17</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.6745</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cjmcginnis</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica yes, nearly every time I fly VX...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24-02-2015 11:13</td>\n",
       "      <td>San Francisco CA</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       tweet_id airline_sentiment  airline_sentiment_confidence  \\\n",
       "0  5.703010e+17          positive                        0.3486   \n",
       "1  5.703010e+17          negative                        1.0000   \n",
       "2  5.703010e+17          negative                        1.0000   \n",
       "3  5.703010e+17          negative                        1.0000   \n",
       "4  5.703010e+17          positive                        0.6745   \n",
       "\n",
       "  negativereason  negativereason_confidence         airline  \\\n",
       "0            NaN                     0.0000  Virgin America   \n",
       "1     Bad Flight                     0.7033  Virgin America   \n",
       "2     Can't Tell                     1.0000  Virgin America   \n",
       "3     Can't Tell                     0.6842  Virgin America   \n",
       "4            NaN                     0.0000  Virgin America   \n",
       "\n",
       "  airline_sentiment_gold        name negativereason_gold  retweet_count  \\\n",
       "0                    NaN    jnardino                 NaN              0   \n",
       "1                    NaN    jnardino                 NaN              0   \n",
       "2                    NaN    jnardino                 NaN              0   \n",
       "3                    NaN    jnardino                 NaN              0   \n",
       "4                    NaN  cjmcginnis                 NaN              0   \n",
       "\n",
       "                                                text tweet_coord  \\\n",
       "0  @VirginAmerica plus you've added commercials t...         NaN   \n",
       "1  @VirginAmerica it's really aggressive to blast...         NaN   \n",
       "2  @VirginAmerica and it's a really big bad thing...         NaN   \n",
       "3  @VirginAmerica seriously would pay $30 a fligh...         NaN   \n",
       "4  @VirginAmerica yes, nearly every time I fly VX...         NaN   \n",
       "\n",
       "      tweet_created    tweet_location               user_timezone  \n",
       "0  24-02-2015 11:15               NaN  Pacific Time (US & Canada)  \n",
       "1  24-02-2015 11:15               NaN  Pacific Time (US & Canada)  \n",
       "2  24-02-2015 11:14               NaN  Pacific Time (US & Canada)  \n",
       "3  24-02-2015 11:14               NaN  Pacific Time (US & Canada)  \n",
       "4  24-02-2015 11:13  San Francisco CA  Pacific Time (US & Canada)  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TeweetData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "TeweetDataSubset = TeweetData[[\"text\",\"airline_sentiment\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>airline_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@VirginAmerica it's really aggressive to blast...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@VirginAmerica and it's a really big bad thing...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@VirginAmerica seriously would pay $30 a fligh...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@VirginAmerica yes, nearly every time I fly VX...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text airline_sentiment\n",
       "0  @VirginAmerica plus you've added commercials t...          positive\n",
       "1  @VirginAmerica it's really aggressive to blast...          negative\n",
       "2  @VirginAmerica and it's a really big bad thing...          negative\n",
       "3  @VirginAmerica seriously would pay $30 a fligh...          negative\n",
       "4  @VirginAmerica yes, nearly every time I fly VX...          positive"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TeweetDataSubset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\LENOVO\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download(\"stopwords\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words(\"english\"))\n",
    "#print(stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordnet = WordNetLemmatizer()\n",
    "def text_preproc(x):\n",
    "  x = x.lower()\n",
    "  x = ' '.join([word for word in x.split(' ') if word not in stop_words])\n",
    "  x = x.encode('ascii', 'ignore').decode()\n",
    "  x = re.sub(r'https*\\S+', ' ', x)\n",
    "  x = re.sub(r'@\\S+', ' ', x)\n",
    "  x = re.sub(r'#\\S+', ' ', x)\n",
    "  x = re.sub(r'\\'\\w+', '', x)\n",
    "  x = re.sub('[%s]' % re.escape(string.punctuation), ' ', x)\n",
    "  x = re.sub(r'\\w*\\d+\\w*', '', x)\n",
    "  x = re.sub(r'\\s{2,}', ' ', x)\n",
    "  return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>airline_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@VirginAmerica it's really aggressive to blast...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@VirginAmerica and it's a really big bad thing...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@VirginAmerica seriously would pay $30 a fligh...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@VirginAmerica yes, nearly every time I fly VX...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>@virginamerica Well, I didn't‚Ä¶but NOW I DO! :-D</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>@VirginAmerica it was amazing, and arrived an ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>@VirginAmerica I &amp;lt;3 pretty graphics. so muc...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>@VirginAmerica This is such a great deal! Alre...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>@VirginAmerica @virginmedia I'm flying your #f...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text airline_sentiment\n",
       "0  @VirginAmerica plus you've added commercials t...          positive\n",
       "1  @VirginAmerica it's really aggressive to blast...          negative\n",
       "2  @VirginAmerica and it's a really big bad thing...          negative\n",
       "3  @VirginAmerica seriously would pay $30 a fligh...          negative\n",
       "4  @VirginAmerica yes, nearly every time I fly VX...          positive\n",
       "5    @virginamerica Well, I didn't‚Ä¶but NOW I DO! :-D          positive\n",
       "6  @VirginAmerica it was amazing, and arrived an ...          positive\n",
       "7  @VirginAmerica I &lt;3 pretty graphics. so muc...          positive\n",
       "8  @VirginAmerica This is such a great deal! Alre...          positive\n",
       "9  @VirginAmerica @virginmedia I'm flying your #f...          positive"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TeweetDataSubset.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "TeweetDataSubset['clean_text'] = TeweetDataSubset.text.apply(text_preproc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
       "      <td>positive</td>\n",
       "      <td>plus added commercials experience tacky</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@VirginAmerica it's really aggressive to blast...</td>\n",
       "      <td>negative</td>\n",
       "      <td>really aggressive blast obnoxious entertainme...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@VirginAmerica and it's a really big bad thing...</td>\n",
       "      <td>negative</td>\n",
       "      <td>really big bad thing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@VirginAmerica seriously would pay $30 a fligh...</td>\n",
       "      <td>negative</td>\n",
       "      <td>seriously would pay flight seats playing it r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@VirginAmerica yes, nearly every time I fly VX...</td>\n",
       "      <td>positive</td>\n",
       "      <td>yes nearly every time fly vx ear worm wont go...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>@virginamerica Well, I didn't‚Ä¶but NOW I DO! :-D</td>\n",
       "      <td>positive</td>\n",
       "      <td>well didn do d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>@VirginAmerica it was amazing, and arrived an ...</td>\n",
       "      <td>positive</td>\n",
       "      <td>amazing arrived hour early good me</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>@VirginAmerica I &amp;lt;3 pretty graphics. so muc...</td>\n",
       "      <td>positive</td>\n",
       "      <td>lt pretty graphics much better minimal iconog...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>@VirginAmerica This is such a great deal! Alre...</td>\n",
       "      <td>positive</td>\n",
       "      <td>great deal already thinking trip amp even gon...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>@VirginAmerica @virginmedia I'm flying your #f...</td>\n",
       "      <td>positive</td>\n",
       "      <td>i flying skies again u take away travel</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text airline_sentiment  \\\n",
       "0  @VirginAmerica plus you've added commercials t...          positive   \n",
       "1  @VirginAmerica it's really aggressive to blast...          negative   \n",
       "2  @VirginAmerica and it's a really big bad thing...          negative   \n",
       "3  @VirginAmerica seriously would pay $30 a fligh...          negative   \n",
       "4  @VirginAmerica yes, nearly every time I fly VX...          positive   \n",
       "5    @virginamerica Well, I didn't‚Ä¶but NOW I DO! :-D          positive   \n",
       "6  @VirginAmerica it was amazing, and arrived an ...          positive   \n",
       "7  @VirginAmerica I &lt;3 pretty graphics. so muc...          positive   \n",
       "8  @VirginAmerica This is such a great deal! Alre...          positive   \n",
       "9  @VirginAmerica @virginmedia I'm flying your #f...          positive   \n",
       "\n",
       "                                          clean_text  \n",
       "0           plus added commercials experience tacky   \n",
       "1   really aggressive blast obnoxious entertainme...  \n",
       "2                               really big bad thing  \n",
       "3   seriously would pay flight seats playing it r...  \n",
       "4   yes nearly every time fly vx ear worm wont go...  \n",
       "5                                     well didn do d  \n",
       "6                amazing arrived hour early good me   \n",
       "7   lt pretty graphics much better minimal iconog...  \n",
       "8   great deal already thinking trip amp even gon...  \n",
       "9           i flying skies again u take away travel   "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TeweetDataSubset.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic ML model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SPLITTING THE TRAINING DATASET INTO TRAIN AND TEST\n",
    "X_train, X_test, y_train, y_test = train_test_split(TeweetDataSubset[\"clean_text\"],TeweetDataSubset[\"airline_sentiment\"],test_size=0.1,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tf-Idf\n",
    "tfidf_vectorizer = TfidfVectorizer(use_idf=True,max_features=10)\n",
    "X_train_vectors_tfidf = tfidf_vectorizer.fit_transform(X_train) \n",
    "X_test_vectors_tfidf = tfidf_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.98      0.90       933\n",
      "    positive       0.67      0.21      0.32       222\n",
      "\n",
      "    accuracy                           0.83      1155\n",
      "   macro avg       0.75      0.59      0.61      1155\n",
      "weighted avg       0.81      0.83      0.79      1155\n",
      "\n",
      "Confusion Matrix:\n",
      " [[910  23]\n",
      " [176  46]]\n"
     ]
    }
   ],
   "source": [
    "lr_tfidf=MultinomialNB()\n",
    "lr_tfidf.fit(X_train_vectors_tfidf, y_train)  \n",
    "\n",
    "#Predict y value for test dataset\n",
    "y_predict = lr_tfidf.predict(X_test_vectors_tfidf)\n",
    "y_prob = lr_tfidf.predict_proba(X_test_vectors_tfidf)[:,1]\n",
    "print(classification_report(y_test,y_predict))\n",
    "print('Confusion Matrix:\\n',confusion_matrix(y_test, y_predict))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Iterable over raw text documents expected, string object received.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_22656\\1249036240.py\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mtmp_x\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"I am not happy\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mtrnsform\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtfidf_vectorizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtmp_x\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[0mtrnsform\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, raw_documents, y)\u001b[0m\n\u001b[0;32m   1821\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1822\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_warn_for_unused_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1823\u001b[1;33m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mraw_documents\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1824\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_tfidf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1825\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001b[0m in \u001b[0;36mfit_transform\u001b[1;34m(self, raw_documents, y)\u001b[0m\n\u001b[0;32m   1190\u001b[0m         \u001b[1;31m# TfidfVectorizer.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1191\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mraw_documents\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1192\u001b[1;33m             raise ValueError(\n\u001b[0m\u001b[0;32m   1193\u001b[0m                 \u001b[1;34m\"Iterable over raw text documents expected, \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1194\u001b[0m                 \"string object received.\")\n",
      "\u001b[1;31mValueError\u001b[0m: Iterable over raw text documents expected, string object received."
     ]
    }
   ],
   "source": [
    "# str = tfidf_vectorizer.fit_transform([\"I am not Happy\"]) \n",
    "# # str = [\"I am not Happy\"]\n",
    "\n",
    "# pred = lr_tfidf.predict(str)\n",
    "# pred\n",
    "\n",
    "tmp_x = \"I am not happy\"\n",
    "trnsform = tfidf_vectorizer.fit(tmp_x)\n",
    "trnsform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HYBRID model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('flight', 3315),\n",
       " ('i', 1104),\n",
       " ('get', 1102),\n",
       " ('cancelled', 956),\n",
       " ('thanks', 920),\n",
       " ('service', 909),\n",
       " ('customer', 724),\n",
       " ('time', 695),\n",
       " ('help', 686),\n",
       " ('hours', 656),\n",
       " ('hold', 621),\n",
       " ('plane', 584),\n",
       " ('amp', 582),\n",
       " ('us', 567),\n",
       " ('thank', 535),\n",
       " ('still', 529),\n",
       " ('delayed', 517),\n",
       " ('can', 502),\n",
       " ('one', 492),\n",
       " ('flights', 478),\n",
       " ('call', 477),\n",
       " ('gate', 476),\n",
       " ('hour', 467),\n",
       " ('flightled', 460),\n",
       " ('you', 456),\n",
       " ('bag', 448),\n",
       " ('back', 448),\n",
       " ('would', 438),\n",
       " ('got', 399),\n",
       " ('late', 395),\n",
       " ('phone', 392),\n",
       " ('need', 391),\n",
       " ('please', 386),\n",
       " ('airline', 374),\n",
       " ('like', 353),\n",
       " ('today', 351),\n",
       " ('waiting', 351),\n",
       " ('guys', 334),\n",
       " ('great', 317),\n",
       " ('that', 316),\n",
       " ('wait', 307),\n",
       " ('u', 306),\n",
       " ('never', 304),\n",
       " ('fly', 303),\n",
       " ('me', 303),\n",
       " ('day', 303),\n",
       " ('trying', 302),\n",
       " ('it', 291),\n",
       " ('delay', 288),\n",
       " ('really', 283),\n",
       " ('airport', 283),\n",
       " ('minutes', 278),\n",
       " ('even', 274),\n",
       " ('going', 271),\n",
       " ('people', 268),\n",
       " ('last', 262),\n",
       " ('way', 262),\n",
       " ('bags', 259),\n",
       " ('weather', 257),\n",
       " ('good', 254),\n",
       " ('know', 254),\n",
       " ('agent', 254),\n",
       " ('home', 252),\n",
       " ('make', 252),\n",
       " ('told', 251),\n",
       " ('luggage', 250),\n",
       " ('another', 244),\n",
       " ('go', 240),\n",
       " ('now', 236),\n",
       " ('ever', 235),\n",
       " ('lost', 235),\n",
       " ('worst', 234),\n",
       " ('flying', 233),\n",
       " ('seat', 232),\n",
       " ('w', 229),\n",
       " ('change', 227),\n",
       " ('check', 226),\n",
       " ('take', 222),\n",
       " ('want', 220),\n",
       " ('hrs', 219),\n",
       " ('due', 218),\n",
       " ('crew', 218),\n",
       " ('getting', 214),\n",
       " ('first', 212),\n",
       " ('days', 212),\n",
       " ('flighted', 211),\n",
       " ('united', 209),\n",
       " ('someone', 208),\n",
       " ('baggage', 207),\n",
       " ('again', 205),\n",
       " ('work', 205),\n",
       " ('much', 204),\n",
       " ('we', 202),\n",
       " ('tomorrow', 202),\n",
       " ('made', 198),\n",
       " ('experience', 197),\n",
       " ('response', 196),\n",
       " ('let', 196),\n",
       " ('could', 193),\n",
       " ('new', 193)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Adding regular expression to data\n",
    "import re\n",
    "from collections import Counter\n",
    "Counter(\" \".join(TeweetDataSubset['clean_text']).split()).most_common(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "Postive_pattern_1 = r\"thanks\"\n",
    "Postive_pattern_2 = r\"thank\"\n",
    "Postive_pattern_3 = r\"great\"\n",
    "Postive_pattern_4 = r\"good\"\n",
    "Postive_pattern_5 = r\"safe\"\n",
    "Postive_pattern_6 = r\"awesome\"\n",
    "Postive_pattern_7 = r\"new\"\n",
    "Postive_pattern_8 = r\"satisfied\"\n",
    "\n",
    "Positive_Pattern_List = [Postive_pattern_1,Postive_pattern_2,Postive_pattern_3,Postive_pattern_4,\n",
    "                        Postive_pattern_5,Postive_pattern_6,Postive_pattern_7,Postive_pattern_8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "Positive_Complex_Pattern = re.compile('|'.join(['(%s)' % i for i in Positive_Pattern_List]),re.IGNORECASE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "Negative_pattern_1 = r\"cancelled\"\n",
    "Negative_pattern_2 = r\"delayed\"\n",
    "Negative_pattern_3 = r\"trying\"\n",
    "Negative_pattern_4 = r\"please\"\n",
    "Negative_pattern_5 = r\"wait\"\n",
    "Negative_pattern_6 = r\"worst\"\n",
    "Negative_pattern_7 = r\"lost\"\n",
    "Negative_pattern_8 = r\"never\"\n",
    "Negative_pattern_9 = r\"fraud trans\"\n",
    "\n",
    "Negative_Pattern_List = [Negative_pattern_1,Negative_pattern_2,Negative_pattern_3,Negative_pattern_4,\n",
    "                        Negative_pattern_5,Negative_pattern_6,Negative_pattern_7,Negative_pattern_8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "Negative_Complex_Pattern = re.compile('|'.join(['(%s)' % i for i in Negative_Pattern_List]),re.IGNORECASE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "TeweetDataSubset[\"Negative_Sentiment_Flag\"] = TeweetDataSubset[\"clean_text\"].apply(lambda x:1 if(len(re.findall(Negative_Complex_Pattern,x))>0) else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "TeweetDataSubset[\"Positive_Sentiment_Flag\"] = TeweetDataSubset[\"clean_text\"].apply(lambda x:1 if(len(re.findall(Positive_Complex_Pattern,x))>0) else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>Negative_Sentiment_Flag</th>\n",
       "      <th>Positive_Sentiment_Flag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
       "      <td>positive</td>\n",
       "      <td>plus added commercials experience tacky</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@VirginAmerica it's really aggressive to blast...</td>\n",
       "      <td>negative</td>\n",
       "      <td>really aggressive blast obnoxious entertainme...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@VirginAmerica and it's a really big bad thing...</td>\n",
       "      <td>negative</td>\n",
       "      <td>really big bad thing</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@VirginAmerica seriously would pay $30 a fligh...</td>\n",
       "      <td>negative</td>\n",
       "      <td>seriously would pay flight seats playing it r...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@VirginAmerica yes, nearly every time I fly VX...</td>\n",
       "      <td>positive</td>\n",
       "      <td>yes nearly every time fly vx ear worm wont go...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>@virginamerica Well, I didn't‚Ä¶but NOW I DO! :-D</td>\n",
       "      <td>positive</td>\n",
       "      <td>well didn do d</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>@VirginAmerica it was amazing, and arrived an ...</td>\n",
       "      <td>positive</td>\n",
       "      <td>amazing arrived hour early good me</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>@VirginAmerica I &amp;lt;3 pretty graphics. so muc...</td>\n",
       "      <td>positive</td>\n",
       "      <td>lt pretty graphics much better minimal iconog...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>@VirginAmerica This is such a great deal! Alre...</td>\n",
       "      <td>positive</td>\n",
       "      <td>great deal already thinking trip amp even gon...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>@VirginAmerica @virginmedia I'm flying your #f...</td>\n",
       "      <td>positive</td>\n",
       "      <td>i flying skies again u take away travel</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>@VirginAmerica Thanks!</td>\n",
       "      <td>positive</td>\n",
       "      <td>thanks</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>@VirginAmerica SFO-PDX schedule is still MIA.</td>\n",
       "      <td>negative</td>\n",
       "      <td>sfo pdx schedule still mia</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>@VirginAmerica So excited for my first cross c...</td>\n",
       "      <td>positive</td>\n",
       "      <td>excited first cross country flight lax mco i ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>@VirginAmerica  I flew from NYC to SFO last we...</td>\n",
       "      <td>negative</td>\n",
       "      <td>flew nyc sfo last week fully sit seat due two...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>I ‚ù§Ô∏è flying @VirginAmerica. ‚ò∫Ô∏èüëç</td>\n",
       "      <td>positive</td>\n",
       "      <td>flying</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>@VirginAmerica you know what would be amazingl...</td>\n",
       "      <td>positive</td>\n",
       "      <td>know would amazingly awesome bos fll please w...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>@VirginAmerica why are your first fares in May...</td>\n",
       "      <td>negative</td>\n",
       "      <td>first fares may three times carriers seats av...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>@VirginAmerica I love this graphic. http://t.c...</td>\n",
       "      <td>positive</td>\n",
       "      <td>love graphic</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>@VirginAmerica I love the hipster innovation. ...</td>\n",
       "      <td>positive</td>\n",
       "      <td>love hipster innovation feel good brand</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>@VirginAmerica you guys messed up my seating.....</td>\n",
       "      <td>negative</td>\n",
       "      <td>guys messed seating reserved seating friends ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text airline_sentiment  \\\n",
       "0   @VirginAmerica plus you've added commercials t...          positive   \n",
       "1   @VirginAmerica it's really aggressive to blast...          negative   \n",
       "2   @VirginAmerica and it's a really big bad thing...          negative   \n",
       "3   @VirginAmerica seriously would pay $30 a fligh...          negative   \n",
       "4   @VirginAmerica yes, nearly every time I fly VX...          positive   \n",
       "5     @virginamerica Well, I didn't‚Ä¶but NOW I DO! :-D          positive   \n",
       "6   @VirginAmerica it was amazing, and arrived an ...          positive   \n",
       "7   @VirginAmerica I &lt;3 pretty graphics. so muc...          positive   \n",
       "8   @VirginAmerica This is such a great deal! Alre...          positive   \n",
       "9   @VirginAmerica @virginmedia I'm flying your #f...          positive   \n",
       "10                             @VirginAmerica Thanks!          positive   \n",
       "11      @VirginAmerica SFO-PDX schedule is still MIA.          negative   \n",
       "12  @VirginAmerica So excited for my first cross c...          positive   \n",
       "13  @VirginAmerica  I flew from NYC to SFO last we...          negative   \n",
       "14                    I ‚ù§Ô∏è flying @VirginAmerica. ‚ò∫Ô∏èüëç          positive   \n",
       "15  @VirginAmerica you know what would be amazingl...          positive   \n",
       "16  @VirginAmerica why are your first fares in May...          negative   \n",
       "17  @VirginAmerica I love this graphic. http://t.c...          positive   \n",
       "18  @VirginAmerica I love the hipster innovation. ...          positive   \n",
       "19  @VirginAmerica you guys messed up my seating.....          negative   \n",
       "\n",
       "                                           clean_text  \\\n",
       "0            plus added commercials experience tacky    \n",
       "1    really aggressive blast obnoxious entertainme...   \n",
       "2                                really big bad thing   \n",
       "3    seriously would pay flight seats playing it r...   \n",
       "4    yes nearly every time fly vx ear worm wont go...   \n",
       "5                                      well didn do d   \n",
       "6                 amazing arrived hour early good me    \n",
       "7    lt pretty graphics much better minimal iconog...   \n",
       "8    great deal already thinking trip amp even gon...   \n",
       "9            i flying skies again u take away travel    \n",
       "10                                            thanks    \n",
       "11                        sfo pdx schedule still mia    \n",
       "12   excited first cross country flight lax mco i ...   \n",
       "13   flew nyc sfo last week fully sit seat due two...   \n",
       "14                                            flying    \n",
       "15   know would amazingly awesome bos fll please w...   \n",
       "16   first fares may three times carriers seats av...   \n",
       "17                                      love graphic    \n",
       "18           love hipster innovation feel good brand    \n",
       "19   guys messed seating reserved seating friends ...   \n",
       "\n",
       "    Negative_Sentiment_Flag  Positive_Sentiment_Flag  \n",
       "0                         0                        0  \n",
       "1                         0                        0  \n",
       "2                         0                        0  \n",
       "3                         0                        0  \n",
       "4                         0                        0  \n",
       "5                         0                        0  \n",
       "6                         0                        1  \n",
       "7                         0                        0  \n",
       "8                         0                        1  \n",
       "9                         0                        0  \n",
       "10                        0                        1  \n",
       "11                        0                        0  \n",
       "12                        0                        1  \n",
       "13                        0                        0  \n",
       "14                        0                        0  \n",
       "15                        1                        1  \n",
       "16                        0                        0  \n",
       "17                        0                        0  \n",
       "18                        0                        1  \n",
       "19                        0                        0  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TeweetDataSubset.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SPLITTING THE TRAINING DATASET INTO TRAIN AND TEST\n",
    "X_train, X_test, y_train, y_test = train_test_split(TeweetDataSubset[[\"clean_text\",\"Negative_Sentiment_Flag\",\"Positive_Sentiment_Flag\"]],TeweetDataSubset[\"airline_sentiment\"],test_size=0.1,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tf-Idf\n",
    "tfidf_vectorizer = TfidfVectorizer(use_idf=True,max_features = 10)\n",
    "X_train_vectors_tfidf = tfidf_vectorizer.fit_transform(X_train[\"clean_text\"]) \n",
    "X_test_vectors_tfidf = tfidf_vectorizer.transform(X_test[\"clean_text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "mydf = pd.DataFrame(X_train_vectors_tfidf.toarray())\n",
    "mydf_test = pd.DataFrame(X_test_vectors_tfidf.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "flag_columns_train = X_train[[\"Negative_Sentiment_Flag\",\"Positive_Sentiment_Flag\"]]\n",
    "flag_columns_test = X_test[[\"Negative_Sentiment_Flag\",\"Positive_Sentiment_Flag\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_vectors_tfidf_combined_with_flag = pd.concat([mydf.reset_index(drop=True),flag_columns_train.reset_index(drop=True)],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_vectors_tfidf_combined_with_flag = pd.concat([mydf_test.reset_index(drop=True),flag_columns_test.reset_index(drop=True)],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.95      0.91       906\n",
      "    positive       0.72      0.46      0.56       249\n",
      "\n",
      "    accuracy                           0.84      1155\n",
      "   macro avg       0.79      0.70      0.73      1155\n",
      "weighted avg       0.83      0.84      0.83      1155\n",
      "\n",
      "Confusion Matrix: [[861  45]\n",
      " [135 114]]\n"
     ]
    }
   ],
   "source": [
    "lr_tfidf=MultinomialNB()\n",
    "lr_tfidf.fit(X_train_vectors_tfidf_combined_with_flag, y_train)  \n",
    "\n",
    "#Predict y value for test dataset\n",
    "y_predict = lr_tfidf.predict(X_test_vectors_tfidf_combined_with_flag)\n",
    "y_prob = lr_tfidf.predict_proba(X_test_vectors_tfidf_combined_with_flag)[:,1]\n",
    "print(classification_report(y_test,y_predict))\n",
    "print('Confusion Matrix:',confusion_matrix(y_test, y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
